{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentos mátematicos de la IA\n",
    "\n",
    "La Inteligencia Artificial (IA) y el Machine Learning se fundamentan en diversas ramas de las matemáticas. Estas herramientas permiten modelar datos, optimizar funciones y comprender patrones complejos. Los principales pilares matemáticos que se utilizan en IA son:\n",
    "\n",
    "- **Probabilidad y Estadística:** Para modelar la incertidumbre, analizar datos y hacer inferencias.\n",
    "- **Cálculo:** Fundamental en la optimización de modelos (por ejemplo, en el ajuste de parámetros mediante gradientes).\n",
    "- **Álgebra Lineal:** Esencial para representar datos en forma de vectores y matrices, y para operaciones que se utilizan en algoritmos de aprendizaje.\n",
    "\n",
    "A continuación, desarrollaremos cada uno de estos temas en detalle.\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Probabilidad\n",
    "\n",
    "La probabilidad es la rama de las matemáticas que estudia la incertidumbre y se utiliza para modelar eventos aleatorios.\n",
    "\n",
    "## 1.1 Conceptos Básicos\n",
    "\n",
    "### Espacio Muestral y Eventos\n",
    "\n",
    "- **Espacio muestral (S):** Es el conjunto de todos los posibles resultados de un experimento aleatorio.  \n",
    "  Ejemplo: Para el lanzamiento de un dado, \\( S = \\{1, 2, 3, 4, 5, 6\\} \\).\n",
    "\n",
    "- **Evento (A):** Es un subconjunto del espacio muestral.  \n",
    "  Ejemplo: Sacar un número par: \\( A = \\{2, 4, 6\\} \\).\n",
    "\n",
    "### Definición de Probabilidad\n",
    "\n",
    "La probabilidad de un evento \\( A \\) se define como:\n",
    "\n",
    "\\[\n",
    "P(A) = \\frac{\\text{Número de resultados favorables a } A}{\\text{Número total de resultados en } S}\n",
    "\\]\n",
    "\n",
    "#### Ejemplo 1.1:  \n",
    "Para el dado:  \n",
    "- Número total de resultados: 6.  \n",
    "- Número de resultados favorables para obtener un número par: 3 (2, 4 y 6).  \n",
    "\n",
    "\\[\n",
    "P(\\text{par}) = \\frac{3}{6} = 0.5\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2 Variables Aleatorias y Funciones de Distribución\n",
    "\n",
    "### Variable Aleatoria  \n",
    "Una variable aleatoria es una función que asigna un número real a cada resultado del espacio muestral.\n",
    "\n",
    "#### Ejemplo:\n",
    "En el lanzamiento de un dado, definimos la variable aleatoria \\( X \\) que toma el valor del número obtenido.\n",
    "\n",
    "### Función de Probabilidad (para variables discretas)\n",
    "\n",
    "La función de probabilidad \\( p(x) \\) asigna la probabilidad de que \\( X \\) tome un valor \\( x \\):\n",
    "\n",
    "\\[\n",
    "p(x) = P(X = x)\n",
    "\\]\n",
    "\n",
    "Para el dado, \\( p(x) = \\frac{1}{6} \\) para \\( x = 1, 2, \\dots, 6 \\).\n",
    "\n",
    "### Función de Distribución Acumulada (CDF)\n",
    "\n",
    "La función de distribución acumulada \\( F(x) \\) se define como:\n",
    "\n",
    "\\[\n",
    "F(x) = P(X \\leq x) = \\sum_{t \\le x} p(t)\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 1.3 Esperanza, Varianza y Desviación Estándar\n",
    "\n",
    "### Esperanza o Valor Esperado\n",
    "\n",
    "La esperanza \\( E[X] \\) de una variable aleatoria \\( X \\) es el promedio ponderado de todos los valores posibles, con sus probabilidades:\n",
    "\n",
    "\\[\n",
    "E[X] = \\sum_{i} x_i \\, p(x_i)\n",
    "\\]\n",
    "\n",
    "#### Ejemplo 1.2:  \n",
    "Para el dado, el valor esperado es:\n",
    "\n",
    "\\[\n",
    "E[X] = \\frac{1 + 2 + 3 + 4 + 5 + 6}{6} = \\frac{21}{6} = 3.5\n",
    "\\]\n",
    "\n",
    "### Varianza\n",
    "\n",
    "La varianza \\( \\operatorname{Var}(X) \\) mide la dispersión de la variable respecto a su media:\n",
    "\n",
    "\\[\n",
    "\\operatorname{Var}(X) = E[(X - E[X])^2] = \\sum_{i} (x_i - E[X])^2 \\, p(x_i)\n",
    "\\]\n",
    "\n",
    "#### Ejemplo 1.3:\n",
    "Para el dado, usando \\( E[X]=3.5 \\):\n",
    "\n",
    "\\[\n",
    "\\operatorname{Var}(X) = \\frac{(1-3.5)^2 + (2-3.5)^2 + (3-3.5)^2 + (4-3.5)^2 + (5-3.5)^2 + (6-3.5)^2}{6}\n",
    "\\]\n",
    "\\[\n",
    "= \\frac{(2.5)^2 + (1.5)^2 + (0.5)^2 + (0.5)^2 + (1.5)^2 + (2.5)^2}{6} \n",
    "= \\frac{6.25 + 2.25 + 0.25 + 0.25 + 2.25 + 6.25}{6} = \\frac{17.5}{6} \\approx 2.92\n",
    "\\]\n",
    "\n",
    "### Desviación Estándar\n",
    "\n",
    "La desviación estándar \\( \\sigma \\) es la raíz cuadrada de la varianza:\n",
    "\n",
    "\\[\n",
    "\\sigma = \\sqrt{\\operatorname{Var}(X)}\n",
    "\\]\n",
    "\\[\n",
    "\\sigma \\approx \\sqrt{2.92} \\approx 1.71\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 1.4 Distribuciones de Probabilidad Comunes\n",
    "\n",
    "### Distribución Binomial\n",
    "\n",
    "Se utiliza para modelar el número de éxitos en \\( n \\) ensayos independientes, cada uno con probabilidad \\( p \\) de éxito.\n",
    "\n",
    "La función de probabilidad es:\n",
    "\n",
    "\\[\n",
    "P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\n",
    "\\]\n",
    "\n",
    "donde:\n",
    "- \\( \\binom{n}{k} = \\frac{n!}{k!(n-k)!} \\) es el coeficiente binomial,\n",
    "- \\( n \\) es el número total de ensayos,\n",
    "- \\( k \\) es el número de éxitos.\n",
    "\n",
    "#### Ejemplo 1.4:\n",
    "Supongamos 10 lanzamientos de una moneda justa (\\( p=0.5 \\)), la probabilidad de obtener 6 caras:\n",
    "\n",
    "\\[\n",
    "P(X = 6) = \\binom{10}{6} (0.5)^6 (0.5)^4 = \\binom{10}{6} (0.5)^{10}\n",
    "\\]\n",
    "\\[\n",
    "\\binom{10}{6} = \\frac{10!}{6!4!} = 210, \\quad \\text{entonces } P(X = 6) = 210 \\times (0.5)^{10} = 210 \\times \\frac{1}{1024} \\approx 0.205\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Estadística\n",
    "\n",
    "La estadística se ocupa de recolectar, analizar e interpretar datos. Es crucial en la IA para la toma de decisiones basadas en datos.\n",
    "\n",
    "## 2.1 Medidas Descriptivas\n",
    "\n",
    "### Media\n",
    "\n",
    "La media (o promedio) de un conjunto de datos \\( x_1, x_2, \\dots, x_n \\) es:\n",
    "\n",
    "\\[\n",
    "\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n",
    "\\]\n",
    "\n",
    "#### Ejemplo 2.1:\n",
    "Para los datos \\( 4, 8, 6, 5, 3 \\):\n",
    "\n",
    "\\[\n",
    "\\bar{x} = \\frac{4+8+6+5+3}{5} = \\frac{26}{5} = 5.2\n",
    "\\]\n",
    "\n",
    "### Mediana\n",
    "\n",
    "La mediana es el valor central de un conjunto de datos ordenado.\n",
    "\n",
    "#### Ejemplo:\n",
    "Para \\( \\{3, 4, 5, 8, 9\\} \\), la mediana es 5.\n",
    "\n",
    "### Moda\n",
    "\n",
    "La moda es el valor que ocurre con mayor frecuencia.\n",
    "\n",
    "#### Ejemplo:\n",
    "En \\( \\{2, 3, 3, 5, 7\\} \\), la moda es 3.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 Inferencia Estadística\n",
    "\n",
    "### Intervalos de Confianza\n",
    "\n",
    "Un intervalo de confianza es un rango de valores que se utiliza para estimar un parámetro poblacional, con un cierto nivel de confianza (por ejemplo, 95%).\n",
    "\n",
    "La fórmula para un intervalo de confianza para la media (cuando la varianza es conocida o el tamaño de la muestra es grande) es:\n",
    "\n",
    "\\[\n",
    "\\bar{x} \\pm Z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
    "\\]\n",
    "\n",
    "donde:\n",
    "- \\( \\bar{x} \\) es la media muestral,\n",
    "- \\( Z_{\\alpha/2} \\) es el valor crítico de la distribución normal (por ejemplo, para 95% es 1.96),\n",
    "- \\( \\sigma \\) es la desviación estándar poblacional,\n",
    "- \\( n \\) es el tamaño de la muestra.\n",
    "\n",
    "#### Ejemplo 2.2:\n",
    "Supongamos que se mide la altura de 100 estudiantes y se obtiene una media de 170 cm con \\( \\sigma = 10 \\) cm. El intervalo de confianza al 95% es:\n",
    "\n",
    "\\[\n",
    "170 \\pm 1.96 \\cdot \\frac{10}{\\sqrt{100}} = 170 \\pm 1.96 \\cdot 1 = 170 \\pm 1.96\n",
    "\\]\n",
    "\\[\n",
    "\\text{Intervalo: } [168.04, 171.96]\n",
    "\\]\n",
    "\n",
    "### Regresión Lineal Simple\n",
    "\n",
    "La regresión lineal modela la relación entre una variable independiente \\( x \\) y una dependiente \\( y \\) usando una línea recta:\n",
    "\n",
    "\\[\n",
    "y = \\beta_0 + \\beta_1 x + \\varepsilon\n",
    "\\]\n",
    "\n",
    "donde:\n",
    "- \\( \\beta_0 \\) es la intersección (ordenada al origen),\n",
    "- \\( \\beta_1 \\) es la pendiente,\n",
    "- \\( \\varepsilon \\) es el término de error.\n",
    "\n",
    "Para estimar \\( \\beta_0 \\) y \\( \\beta_1 \\), se usan las siguientes fórmulas (mínimos cuadrados):\n",
    "\n",
    "\\[\n",
    "\\beta_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\n",
    "\\]\n",
    "\\[\n",
    "\\beta_0 = \\bar{y} - \\beta_1 \\bar{x}\n",
    "\\]\n",
    "\n",
    "#### Ejemplo 2.3:\n",
    "Considera los siguientes datos:\n",
    "- \\( x: 1, 2, 3, 4 \\)\n",
    "- \\( y: 2, 3, 5, 4 \\)\n",
    "\n",
    "Calculamos:\n",
    "- \\( \\bar{x} = \\frac{1+2+3+4}{4} = 2.5 \\)\n",
    "- \\( \\bar{y} = \\frac{2+3+5+4}{4} = 3.5 \\)\n",
    "\n",
    "Calcular \\( \\beta_1 \\):\n",
    "\\[\n",
    "\\sum (x_i - \\bar{x})(y_i - \\bar{y}) = (1-2.5)(2-3.5) + (2-2.5)(3-3.5) + (3-2.5)(5-3.5) + (4-2.5)(4-3.5)\n",
    "\\]\n",
    "\\[\n",
    "= (-1.5)(-1.5) + (-0.5)(-0.5) + (0.5)(1.5) + (1.5)(0.5) = 2.25 + 0.25 + 0.75 + 0.75 = 4\n",
    "\\]\n",
    "\\[\n",
    "\\sum (x_i - \\bar{x})^2 = (-1.5)^2 + (-0.5)^2 + (0.5)^2 + (1.5)^2 = 2.25 + 0.25 + 0.25 + 2.25 = 5\n",
    "\\]\n",
    "\\[\n",
    "\\beta_1 = \\frac{4}{5} = 0.8\n",
    "\\]\n",
    "\\[\n",
    "\\beta_0 = 3.5 - 0.8 \\times 2.5 = 3.5 - 2 = 1.5\n",
    "\\]\n",
    "\n",
    "La ecuación de la recta es:\n",
    "\\[\n",
    "y = 1.5 + 0.8x\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Cálculo\n",
    "\n",
    "El cálculo es fundamental para la optimización en IA, ya que se utiliza para encontrar mínimos y máximos de funciones de pérdida y ajustar parámetros de modelos.\n",
    "\n",
    "## 3.1 Derivadas y Gradiente\n",
    "\n",
    "### Derivada de una Función\n",
    "\n",
    "La derivada de una función \\( f(x) \\) es el límite que define la tasa de cambio instantánea:\n",
    "\n",
    "\\[\n",
    "f'(x) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}\n",
    "\\]\n",
    "\n",
    "#### Ejemplo 3.1:\n",
    "Para \\( f(x) = x^2 \\):\n",
    "\\[\n",
    "f'(x) = \\lim_{h \\to 0} \\frac{(x+h)^2 - x^2}{h} = \\lim_{h \\to 0} \\frac{2xh + h^2}{h} = \\lim_{h \\to 0} (2x + h) = 2x\n",
    "\\]\n",
    "\n",
    "### Gradiente de una Función de Múltiples Variables\n",
    "\n",
    "El gradiente es un vector de derivadas parciales y apunta en la dirección de mayor aumento de la función:\n",
    "\n",
    "\\[\n",
    "\\nabla f(x_1, x_2, \\dots, x_n) = \\left( \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\dots, \\frac{\\partial f}{\\partial x_n} \\right)\n",
    "\\]\n",
    "\n",
    "#### Ejemplo 3.2:\n",
    "Para \\( f(x, y) = x^2 + y^2 \\):\n",
    "\\[\n",
    "\\frac{\\partial f}{\\partial x} = 2x, \\quad \\frac{\\partial f}{\\partial y} = 2y\n",
    "\\]\n",
    "Entonces,  \n",
    "\\[\n",
    "\\nabla f(x, y) = (2x, 2y)\n",
    "\\]\n",
    "\n",
    "### Aplicación en Optimización: Descenso del Gradiente\n",
    "\n",
    "El **descenso del gradiente** es un método para minimizar funciones (por ejemplo, la función de pérdida en un modelo de IA). La regla de actualización para cada parámetro \\( \\theta \\) es:\n",
    "\n",
    "\\[\n",
    "\\theta := \\theta - \\alpha \\nabla f(\\theta)\n",
    "\\]\n",
    "\n",
    "donde:\n",
    "- \\( \\alpha \\) es la tasa de aprendizaje (learning rate),\n",
    "- \\( \\nabla f(\\theta) \\) es el gradiente en \\( \\theta \\).\n",
    "\n",
    "#### Ejemplo 3.3:\n",
    "Supongamos que queremos minimizar \\( f(x) = (x-3)^2 \\).  \n",
    "- La derivada es \\( f'(x) = 2(x-3) \\).  \n",
    "- Con un \\( \\alpha = 0.1 \\) y \\( x_0 = 0 \\), la actualización es:\n",
    "  \\[\n",
    "  x_1 = x_0 - 0.1 \\times 2(0-3) = 0 - 0.1 \\times (-6) = 0 + 0.6 = 0.6\n",
    "  \\]\n",
    "- Repetir el proceso:\n",
    "  \\[\n",
    "  x_2 = 0.6 - 0.1 \\times 2(0.6-3) = 0.6 - 0.1 \\times (-4.8) = 0.6 + 0.48 = 1.08\n",
    "  \\]\n",
    "  \n",
    "El proceso se repite hasta que \\( x \\) se aproxime a 3, que es el mínimo de la función.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Álgebra Lineal\n",
    "\n",
    "El álgebra lineal es esencial para el procesamiento de datos en IA, ya que los datos se representan en forma de vectores y matrices.\n",
    "\n",
    "## 4.1 Vectores y Operaciones\n",
    "\n",
    "Un vector es una lista ordenada de números. Por ejemplo, un vector en \\( \\mathbb{R}^3 \\) se puede escribir como:\n",
    "\n",
    "\\[\n",
    "\\mathbf{v} = \\begin{pmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "### Suma y Producto por Escalar\n",
    "\n",
    "- **Suma de vectores:**  \n",
    "  \\[\n",
    "  \\mathbf{u} + \\mathbf{v} = \\begin{pmatrix} u_1+v_1 \\\\ u_2+v_2 \\\\ u_3+v_3 \\end{pmatrix}\n",
    "  \\]\n",
    "- **Producto por un escalar \\( c \\):**  \n",
    "  \\[\n",
    "  c\\mathbf{v} = \\begin{pmatrix} c \\cdot v_1 \\\\ c \\cdot v_2 \\\\ c \\cdot v_3 \\end{pmatrix}\n",
    "  \\]\n",
    "\n",
    "#### Ejemplo 4.1:\n",
    "Sean \\( \\mathbf{u} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} \\) y \\( \\mathbf{v} = \\begin{pmatrix} 4 \\\\ 5 \\\\ 6 \\end{pmatrix} \\).  \n",
    "- Suma:  \n",
    "  \\[\n",
    "  \\mathbf{u} + \\mathbf{v} = \\begin{pmatrix} 1+4 \\\\ 2+5 \\\\ 3+6 \\end{pmatrix} = \\begin{pmatrix} 5 \\\\ 7 \\\\ 9 \\end{pmatrix}\n",
    "  \\]\n",
    "- Producto por escalar (por 2):  \n",
    "  \\[\n",
    "  2\\mathbf{u} = \\begin{pmatrix} 2\\cdot1 \\\\ 2\\cdot2 \\\\ 2\\cdot3 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 4 \\\\ 6 \\end{pmatrix}\n",
    "  \\]\n",
    "\n",
    "## 4.2 Matrices y Multiplicación\n",
    "\n",
    "Una matriz es una colección de números organizados en filas y columnas. Por ejemplo, una matriz \\( A \\) de dimensión \\( m \\times n \\) es:\n",
    "\n",
    "\\[\n",
    "A = \\begin{pmatrix}\n",
    "a_{11} & a_{12} & \\dots & a_{1n} \\\\\n",
    "a_{21} & a_{22} & \\dots & a_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{m1} & a_{m2} & \\dots & a_{mn}\n",
    "\\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "### Multiplicación de Matrices\n",
    "\n",
    "Si \\( A \\) es de dimensión \\( m \\times n \\) y \\( B \\) es \\( n \\times p \\), el producto \\( C = A \\cdot B \\) es una matriz \\( m \\times p \\) definida como:\n",
    "\n",
    "\\[\n",
    "c_{ij} = \\sum_{k=1}^{n} a_{ik} \\, b_{kj}\n",
    "\\]\n",
    "\n",
    "#### Ejemplo 4.2:\n",
    "Sean\n",
    "\\[\n",
    "A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 5 & 6 \\\\ 7 & 8 \\end{pmatrix}\n",
    "\\]\n",
    "El producto \\( C = A \\cdot B \\) es:\n",
    "\\[\n",
    "c_{11} = 1\\cdot5 + 2\\cdot7 = 5 + 14 = 19\n",
    "\\]\n",
    "\\[\n",
    "c_{12} = 1\\cdot6 + 2\\cdot8 = 6 + 16 = 22\n",
    "\\]\n",
    "\\[\n",
    "c_{21} = 3\\cdot5 + 4\\cdot7 = 15 + 28 = 43\n",
    "\\]\n",
    "\\[\n",
    "c_{22} = 3\\cdot6 + 4\\cdot8 = 18 + 32 = 50\n",
    "\\]\n",
    "Entonces,\n",
    "\\[\n",
    "C = \\begin{pmatrix} 19 & 22 \\\\ 43 & 50 \\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "## 4.3 Eigenvalores y Eigenvectores\n",
    "\n",
    "En muchos algoritmos de IA (por ejemplo, en reducción de dimensionalidad o análisis de componentes principales), se utilizan los eigenvalores y eigenvectores.\n",
    "\n",
    "### Definición\n",
    "\n",
    "Para una matriz cuadrada \\( A \\), un vector no nulo \\( \\mathbf{v} \\) es un eigenvector si existe un escalar \\( \\lambda \\) (eigenvalor) tal que:\n",
    "\n",
    "\\[\n",
    "A\\mathbf{v} = \\lambda \\mathbf{v}\n",
    "\\]\n",
    "\n",
    "Para encontrar \\( \\lambda \\), se resuelve el **polinomio característico**:\n",
    "\\[\n",
    "\\det(A - \\lambda I) = 0\n",
    "\\]\n",
    "donde \\( I \\) es la matriz identidad.\n",
    "\n",
    "#### Ejemplo 4.3:\n",
    "Sea\n",
    "\\[\n",
    "A = \\begin{pmatrix} 4 & 2 \\\\ 1 & 3 \\end{pmatrix}\n",
    "\\]\n",
    "El polinomio característico es:\n",
    "\\[\n",
    "\\det\\left(\\begin{pmatrix} 4-\\lambda & 2 \\\\ 1 & 3-\\lambda \\end{pmatrix}\\right) = (4-\\lambda)(3-\\lambda) - 2\\cdot1 = \\lambda^2 - 7\\lambda + 10 = 0\n",
    "\\]\n",
    "Resolviendo:\n",
    "\\[\n",
    "\\lambda^2 - 7\\lambda + 10 = 0 \\quad \\Rightarrow \\quad (\\lambda - 5)(\\lambda - 2) = 0\n",
    "\\]\n",
    "Por lo tanto, los eigenvalores son \\( \\lambda = 5 \\) y \\( \\lambda = 2 \\).\n",
    "\n",
    "Para \\( \\lambda = 5 \\):\n",
    "\\[\n",
    "(A - 5I)\\mathbf{v} = \\begin{pmatrix} -1 & 2 \\\\ 1 & -2 \\end{pmatrix}\\mathbf{v} = \\mathbf{0}\n",
    "\\]\n",
    "Una solución es \\( \\mathbf{v} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} \\) (después de normalizar si se requiere).\n",
    "\n",
    "---\n",
    "\n",
    "## Recursos adicionales\n",
    "\n",
    "1.  **\"Mathematics for Machine Learning\"** por Marc Peter Deisenroth, A. Aldo Faisal, y Cheng Soon Ong.\n",
    "\n",
    "      * Deisenroth, M. P., Faisal, A. A., & Ong, C. S. (2020). *Mathematics for machine learning*. Cambridge University Press.\n",
    "      * Este libro es una excelente introducción a los conceptos matemáticos necesarios para el aprendizaje automático. Cubre álgebra lineal, cálculo, probabilidad, estadística y optimización, con un enfoque en cómo se aplican estos temas en la IA.  Es muy completo y tiene muchos ejemplos. Es, en mi opinión, la mejor opción de las tres que te presento.\n",
    "\n",
    "2.  **\"The Elements of Statistical Learning: Data Mining, Inference, and Prediction\"** por Trevor Hastie, Robert Tibshirani, y Jerome Friedman.\n",
    "\n",
    "      * Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The elements of statistical learning: Data mining, inference, and prediction* (2nd ed.). Springer.\n",
    "      * Aunque se centra más en el aprendizaje estadístico, este libro es una referencia fundamental. Explica conceptos clave como la regresión, la clasificación, los métodos de regularización, y los modelos lineales generalizados.  Es un clásico, pero puede ser un poco más avanzado. El libro se puede descargar gratuitamente desde la página web de los autores.\n",
    "\n",
    "3.  **\"Linear Algebra and Its Applications\"** por Gilbert Strang.\n",
    "\n",
    "      * Strang, G. (2016). *Linear algebra and its applications* (5th ed.). Wellesley-Cambridge Press.\n",
    "      * Gilbert Strang es reconocido por su habilidad para explicar el álgebra lineal de manera clara y accesible. Este libro es un recurso excelente para dominar los conceptos de vectores, matrices, transformaciones lineales, valores propios y más.  Incluye muchas aplicaciones prácticas.\n",
    "\n",
    "**Recursos en Línea Gratuitos:**\n",
    "\n",
    "1.  **Khan Academy:**\n",
    "      * [https://www.khanacademy.org/](https://www.google.com/url?sa=E&source=gmail&q=https://www.khanacademy.org/)\n",
    "      * Khan Academy ofrece cursos gratuitos en línea sobre álgebra lineal, cálculo, probabilidad y estadística. Los videos son muy didácticos y hay muchos ejercicios para practicar. Es ideal para repasar conceptos o aprender desde cero. Los temas individuales son:\n",
    "          * Álgebra lineal: [https://www.khanacademy.org/math/linear-algebra](https://www.google.com/url?sa=E&source=gmail&q=https://www.khanacademy.org/math/linear-algebra)\n",
    "          * Cálculo: [https://www.khanacademy.org/math/calculus-1](https://www.google.com/url?sa=E&source=gmail&q=https://www.khanacademy.org/math/calculus-1) (y cursos de cálculo más avanzados)\n",
    "          * Probabilidad y estadística: [https://www.khanacademy.org/math/statistics-probability](https://www.google.com/url?sa=E&source=gmail&q=https://www.khanacademy.org/math/statistics-probability)\n",
    "2.  **MIT OpenCourseWare:**\n",
    "      * [https://ocw.mit.edu/](https://www.google.com/url?sa=E&source=gmail&q=https://ocw.mit.edu/)\n",
    "      * El MIT ofrece acceso gratuito a los materiales de muchos de sus cursos, incluyendo cursos de matemáticas relevantes para la IA. Puedes encontrar clases magistrales en video, notas de clase y problemas resueltos. Algunos cursos relevantes:\n",
    "          * 18.06 Linear Algebra (Álgebra Lineal): [https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/](https://www.google.com/url?sa=E&source=gmail&q=https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/) (impartido por Gilbert Strang)\n",
    "          * 6.041 Probabilistic Systems Analysis and Applied Probability (Análisis de Sistemas Probabilísticos y Probabilidad Aplicada): [https://ocw.mit.edu/courses/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/](https://www.google.com/url?sa=E&source=gmail&q=https://ocw.mit.edu/courses/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/)\n",
    "          * 18.065 Matrix Methods in Data Analysis, Signal Processing, and Machine Learning (Métodos Matriciales en Análisis de Datos, Procesamiento de Señales y Aprendizaje Automático): [https://ocw.mit.edu/courses/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/](https://www.google.com/url?sa=E&source=gmail&q=https://ocw.mit.edu/courses/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/)\n",
    "3.  **3Blue1Brown**\n",
    "      * [https://www.youtube.com/c/3blue1brown](https://www.google.com/url?sa=E&source=gmail&q=https://www.youtube.com/c/3blue1brown)\n",
    "      * Es un canal de youtube que realiza animaciones de muy alta calidad sobre temas complejos de matematicas, donde explica de manera sumamente visual, algebra lineal y calculo.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
